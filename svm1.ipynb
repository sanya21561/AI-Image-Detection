{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/Users/brindamuralie/Desktop/Sem5/mlprojec/ml/kaggle/input/train'\n",
    "test_data_path = '/Users/brindamuralie/Desktop/Sem5/mlprojec/ml/kaggle/input/test'\n",
    "\n",
    "# Create empty lists to store image data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Loop through the REAL and FAKE subfolders in the train data directory\n",
    "for folder in os.listdir(train_data_path):\n",
    "    if folder != '.DS_Store':\n",
    "        folder_path = os.path.join(train_data_path, folder)\n",
    "        label = folder  # Label is either 'REAL' or 'FAKE'\n",
    "\n",
    "        # Loop through the images in each subfolder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (32, 32))  # Resize to 32x32 pixels\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "# Convert data and labels to NumPy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an SVM classifier\n",
    "svm_classifier = SVC(probability=True)\n",
    "svm_classifier.fit(X_train.reshape(-1, 32 * 32 * 3), y_train)\n",
    "\n",
    "# Predict on the validation data\n",
    "y_pred_svm = svm_classifier.predict(X_val.reshape(-1, 32 * 32 * 3))\n",
    "\n",
    "# Calculate accuracy on validation data\n",
    "accuracy_svm = accuracy_score(y_val, y_pred_svm)\n",
    "print(\"Validation\")\n",
    "print(f\"Accuracy (SVM): {accuracy_svm}\")\n",
    "\n",
    "# Calculate precision, recall, and F1-Score on validation data for SVM\n",
    "precision_svm = precision_score(y_val, y_pred_svm)\n",
    "recall_svm = recall_score(y_val, y_pred_svm)\n",
    "f1_svm = f1_score(y_val, y_pred_svm)\n",
    "print(f\"Precision (SVM): {precision_svm}\")\n",
    "print(f\"Recall (SVM): {recall_svm}\")\n",
    "print(f\"F1-Score (SVM): {f1_svm}\")\n",
    "\n",
    "# Calculate the confusion matrix on validation data for SVM\n",
    "conf_matrix_svm = confusion_matrix(y_val, y_pred_svm)\n",
    "print(\"Confusion Matrix (SVM):\")\n",
    "print(conf_matrix_svm)\n",
    "\n",
    "# Calculate specificity and false positive rate on validation data for SVM\n",
    "tn_svm, fp_svm, fn_svm, tp_svm = conf_matrix_svm.ravel()\n",
    "specificity_svm = tn_svm / (tn_svm + fp_svm)\n",
    "fpr_svm = fp_svm / (tn_svm + fp_svm)\n",
    "print(f\"Specificity (SVM): {specificity_svm}\")\n",
    "print(f\"False Positive Rate (SVM): {fpr_svm}\")\n",
    "\n",
    "# Calculate decision function scores for ROC and Precision-Recall curves\n",
    "y_scores_svm = svm_classifier.decision_function(X_val.reshape(-1, 32 * 32 * 3))\n",
    "\n",
    "# Calculate ROC curve and AUC-ROC on validation data for SVM\n",
    "fpr_svm, tpr_svm, thresholds_svm = roc_curve(y_val, y_scores_svm)\n",
    "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
    "print(\"ROC Curve and AUC-ROC (SVM):\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label=f'AUC = {roc_auc_svm:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (SVM)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Calculate Precision-Recall curve and AUC-PR on validation data for SVM\n",
    "precision_svm, recall_svm, _ = precision_recall_curve(y_val, y_scores_svm)\n",
    "pr_auc_svm = average_precision_score(y_val, y_scores_svm)\n",
    "print(\"Precision-Recall Curve and AUC-PR (SVM):\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_svm, precision_svm, color='blue', lw=2, label=f'AUC = {pr_auc_svm:.2f}')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve (SVM)')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess test data\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for folder in os.listdir(test_data_path):\n",
    "    folder_path = os.path.join(test_data_path, folder)\n",
    "    label = folder  # Label is either 'REAL' or 'FAKE'\n",
    "    if folder != '.DS_Store':\n",
    "        # Loop through the images in each subfolder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (32, 32))  # Resize to 32x32 pixels\n",
    "            test_data.append(image)\n",
    "            test_labels.append(label)\n",
    "\n",
    "# Convert test data and labels to NumPy arrays\n",
    "test_data = np.array(test_data)\n",
    "test_labels = label_encoder.transform(test_labels)  # Encode test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data using SVM\n",
    "test_scores_svm = svm_classifier.decision_function(test_data.reshape(-1, 32 * 32 * 3))\n",
    "test_pred_svm = svm_classifier.predict(test_data.reshape(-1, 32 * 32 * 3))\n",
    "\n",
    "# Calculate accuracy on the test data using SVM predictions\n",
    "test_accuracy_svm = accuracy_score(test_labels, test_pred_svm)\n",
    "print(\"Test\")\n",
    "print(f\"Test Accuracy (SVM): {test_accuracy_svm}\")\n",
    "\n",
    "# Calculate precision, recall, and F1-Score on test data using SVM predictions\n",
    "precision_svm = precision_score(test_labels, test_pred_svm)\n",
    "recall_svm = recall_score(test_labels, test_pred_svm)\n",
    "f1_svm = f1_score(test_labels, test_pred_svm)\n",
    "print(f\"Precision (SVM): {precision_svm}\")\n",
    "print(f\"Recall (SVM): {recall_svm}\")\n",
    "print(f\"F1-Score (SVM): {f1_svm}\")\n",
    "\n",
    "# Calculate the confusion matrix on test data using SVM predictions\n",
    "conf_matrix_svm = confusion_matrix(test_labels, test_pred_svm)\n",
    "print(\"Confusion Matrix (SVM):\")\n",
    "print(conf_matrix_svm)\n",
    "\n",
    "# Calculate specificity and false positive rate on test data using SVM predictions\n",
    "tn_svm, fp_svm, fn_svm, tp_svm = conf_matrix_svm.ravel()\n",
    "specificity_svm = tn_svm / (tn_svm + fp_svm)\n",
    "fpr_svm = fp_svm / (tn_svm + fp_svm)\n",
    "print(f\"Specificity (SVM): {specificity_svm}\")\n",
    "print(f\"False Positive Rate (SVM): {fpr_svm}\")\n",
    "\n",
    "# Calculate ROC curve and AUC-ROC on test data using SVM scores\n",
    "fpr_svm, tpr_svm, thresholds_svm = roc_curve(test_labels, test_scores_svm)\n",
    "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
    "print(\"ROC Curve and AUC-ROC (SVM):\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label=f'AUC = {roc_auc_svm:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (SVM)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Calculate Precision-Recall curve and AUC-PR on test data using SVM scores\n",
    "precision_svm, recall_svm, _ = precision_recall_curve(test_labels, test_scores_svm)\n",
    "pr_auc_svm = average_precision_score(test_labels, test_scores_svm)\n",
    "print(\"Precision-Recall Curve and AUC-PR (SVM):\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_svm, precision_svm, color='blue', lw=2, label=f'AUC = {pr_auc_svm:.2f}')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve (SVM)')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
